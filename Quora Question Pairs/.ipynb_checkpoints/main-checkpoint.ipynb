{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3257d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8772/264531854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46cd4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0c6d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbbc2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tables(data):\n",
    "    # This gives you an array. as type str as only string values can be concatenated\n",
    "    question1 = df[\"question1\"].astype(str).values\n",
    "    question2 = df[\"question2\"].astype(str).values\n",
    "    df['combined'] = df['question1'] + df['question2']\n",
    "    combined = question1 + question2\n",
    "    labels = df['is_duplicate'].values.astype(\"float32\")\n",
    "    \n",
    "    return question1, question2, labels\n",
    "\n",
    "\n",
    "question1, question2, labels = load_tables(df)\n",
    "\n",
    "question1 = list(question1)\n",
    "question2 = list(question2)\n",
    "combined = question1 + question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0018f369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the step by step guide to invest in share market in india?',\n",
       " 'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
       " 'How can I increase the speed of my internet connection while using a VPN?',\n",
       " 'Why am I mentally very lonely? How can I solve it?',\n",
       " 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n",
       " 'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n",
       " 'Should I buy tiago?',\n",
       " 'How can I be a good geologist?',\n",
       " 'When do you use シ instead of し?',\n",
       " 'Motorola (company): Can I hack my Charter Motorolla DCX3400?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d05d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanASCII(text):\n",
    "    return \"\".join(i for i in text if ord(i) < 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a85f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fox jumped over a cat'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Ä fox jumped over a cat\"\n",
    "cleanASCII(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e9cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model necessarily yields word embeddings as the weights of the first layer, which is usually referred to as Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5692286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676b7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 4000\n",
    "# Out of vocabulary token is named as <OOV>\n",
    "tokenizer = Tokenizer(num_words = num_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(combined)\n",
    "\n",
    "# Assumung the maxlen of word to be 300, that 1169 is fishy. Padding as well.\n",
    "sequences_input1 = tokenizer.texts_to_sequences(question1)\n",
    "sequences_input1 = pad_sequences(sequences_input1, maxlen = 300, padding = \"post\")\n",
    "\n",
    "sequences_input2 = tokenizer.texts_to_sequences(question2)\n",
    "sequences_input2 = pad_sequences(sequences_input2, maxlen = 300, padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8cd97a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word vectors are 400000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "glove_dir = \"\"\n",
    "embeddings_index = {}\n",
    "\n",
    "# char map decoding errors, specify the file format\n",
    "with open(os.path.join(glove_dir, \"glove.6B.50d.txt\"), encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split() # Split by space\n",
    "        \n",
    "        word = values[0]\n",
    "        # Convert the string coefficients to float values and store as numpy array\n",
    "        coeffs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coeffs\n",
    "        \n",
    "        \n",
    "print(f\"Number of word vectors are {len(embeddings_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a03351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95597"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d47e92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the embedding matrix, check online. Rows are the words and columns are the dimensions or word vectors\n",
    "# Number of word dimensions of th gloveModel is 100\n",
    "num_dimensions = 50\n",
    "embeddings_matrix = np.zeros((num_words, num_dimensions))\n",
    "\n",
    "for word_token, i in tokenizer.word_index.items():\n",
    "#     There are 95597 words, but training so many words is hard, hence just choose 10,000 or num_words;\n",
    "    if i < num_words:\n",
    "#         get returns None, whereas just indexing it returns a keyError.\n",
    "        dimension_vector = embeddings_index.get(word_token)\n",
    "#         There may be words, that are not in the glove model, but are in the tokenizer\n",
    "\n",
    "        # The i of this for loop starts as one, as the first token <OOV> is given the index 1. Hence we need to add 1 somewhere to keep\n",
    "        # things consistent.\n",
    "        if dimension_vector is not None:\n",
    "            embeddings_matrix[i] = dimension_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e540a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(32, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "\n",
    "# emb matrix. Glove Vectors, don't train again\n",
    "emb = Embedding(num_words, num_dimensions, input_length = 300, trainable = False, weights = [embeddings_matrix])\n",
    "\n",
    "# 2 things to compare.\n",
    "input1 = Input(shape=(300,))\n",
    "e1 = emb(input1)\n",
    "x1 = lstm_layer(e1)\n",
    "\n",
    "input2 = Input(shape=(300,))\n",
    "e2 = emb(input2)\n",
    "x2 = lstm_layer(e2)\n",
    "\n",
    "mhd = lambda x: tf.keras.backend.abs(x[0] - x[1])\n",
    "\n",
    "# Doubt in this line of code. x[0] and x[1], are the inputs of the array [x1, x2]. A layer has two inputs, so we subtract each training example, x[0] and x[1].\n",
    "# Output shape is x[0], as when we subtract two quantities of same shape etc, we get a result of any of the input shapes. It can also be x[1], it doesn't matter.\n",
    "merged = tf.keras.layers.Lambda(function=mhd, output_shape=lambda x: x[0], name='L1_distance')([x1, x2])\n",
    "\n",
    "# Sigmoid activation to squash our output between 0 and 1.(1 refers to maximum similarity and 0 refers to minimum similarity).\n",
    "preds = tf.keras.layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# Similarity between two pieces of text.\n",
    "model = tf.keras.Model(inputs=[input1, input2], outputs=preds)\n",
    "\n",
    "# Mean square error\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24dfe2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b53cbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='is_duplicate', ylabel='count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df[\"is_duplicate\"][0:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a92c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_input1 = sequences_input1[0:5000]\n",
    "sequences_input2 = sequences_input2[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae657f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df):\n",
    "    features = df.drop(columns=['id', 'qid1', 'qid2', 'is_duplicate']).values\n",
    "    labels = df['is_duplicate'][:5000].values.astype(\"float32\")\n",
    "#     print(features[:10])\n",
    "#     print(labels[:10])\n",
    "    X_train1, X_test1, y_train, y_test = train_test_split(sequences_input1, labels, test_size=0.2, random_state=42)\n",
    "    X_train2, X_test2, y_train, y_test = train_test_split(sequences_input2, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train1, X_test1, y_train, y_test, X_train2, X_test2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cbfdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train, y_test, X_train2, X_test2 = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2fdbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fa9ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 90s 722ms/step - loss: 0.2317 - val_loss: 0.2249\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 86s 686ms/step - loss: 0.2222 - val_loss: 0.2198\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 90s 718ms/step - loss: 0.2184 - val_loss: 0.2150\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 93s 741ms/step - loss: 0.2156 - val_loss: 0.2138\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 96s 768ms/step - loss: 0.2117 - val_loss: 0.2154\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 98s 783ms/step - loss: 0.2081 - val_loss: 0.2151\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 94s 751ms/step - loss: 0.2040 - val_loss: 0.2045\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 90s 720ms/step - loss: 0.2024 - val_loss: 0.2065\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 88s 707ms/step - loss: 0.1994 - val_loss: 0.2012\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1963 - val_loss: 0.2028\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 84s 676ms/step - loss: 0.1943 - val_loss: 0.2038\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 86s 692ms/step - loss: 0.1920 - val_loss: 0.2031\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 84s 674ms/step - loss: 0.1875 - val_loss: 0.2000\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 84s 668ms/step - loss: 0.1884 - val_loss: 0.2040\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 83s 668ms/step - loss: 0.1847 - val_loss: 0.2040\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 84s 671ms/step - loss: 0.1819 - val_loss: 0.2118\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 85s 681ms/step - loss: 0.1815 - val_loss: 0.2004\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 84s 671ms/step - loss: 0.1792 - val_loss: 0.2052\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 84s 668ms/step - loss: 0.1769 - val_loss: 0.2084\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 84s 670ms/step - loss: 0.1752 - val_loss: 0.2054\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 84s 669ms/step - loss: 0.1742 - val_loss: 0.2019\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 88s 705ms/step - loss: 0.1698 - val_loss: 0.2058\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 92s 733ms/step - loss: 0.1698 - val_loss: 0.2095\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 92s 739ms/step - loss: 0.1668 - val_loss: 0.2007\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 100s 802ms/step - loss: 0.1670 - val_loss: 0.2009\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 100s 803ms/step - loss: 0.1665 - val_loss: 0.2047\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.1646 - val_loss: 0.2059\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 0.1651 - val_loss: 0.2078\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 96s 765ms/step - loss: 0.1629 - val_loss: 0.2114\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 84s 671ms/step - loss: 0.1578 - val_loss: 0.2051\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 83s 661ms/step - loss: 0.1570 - val_loss: 0.2080\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 85s 681ms/step - loss: 0.1577 - val_loss: 0.2032\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 85s 676ms/step - loss: 0.1566 - val_loss: 0.2125\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 92s 735ms/step - loss: 0.1557 - val_loss: 0.2024\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 96s 768ms/step - loss: 0.1531 - val_loss: 0.2137\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 99s 796ms/step - loss: 0.1530 - val_loss: 0.2144\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 106s 852ms/step - loss: 0.1525 - val_loss: 0.2050\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 94s 756ms/step - loss: 0.1494 - val_loss: 0.2106\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 88s 700ms/step - loss: 0.1476 - val_loss: 0.2048\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.1508 - val_loss: 0.2081\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 88s 704ms/step - loss: 0.1462 - val_loss: 0.2076\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 85s 683ms/step - loss: 0.1458 - val_loss: 0.2096\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 85s 682ms/step - loss: 0.1446 - val_loss: 0.2125\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 87s 696ms/step - loss: 0.1453 - val_loss: 0.2120\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 85s 679ms/step - loss: 0.1397 - val_loss: 0.2080\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.1396 - val_loss: 0.2149\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 87s 693ms/step - loss: 0.1400 - val_loss: 0.2164\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 87s 700ms/step - loss: 0.1402 - val_loss: 0.2100\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 87s 698ms/step - loss: 0.1363 - val_loss: 0.2090\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 84s 672ms/step - loss: 0.1370 - val_loss: 0.2172\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train1, X_train2], y_train, epochs=50, validation_data=([X_test1,  X_test2], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3834f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e0fed19d60>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss decreases, so we are correct.\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d247f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test1, X_test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d212d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    if x[0] >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "binary_predictions = map(binary, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5098989d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8942049e-01],\n",
       "       [2.5627634e-01],\n",
       "       [7.2096217e-01],\n",
       "       [5.3343177e-04],\n",
       "       [4.2628527e-01],\n",
       "       [7.7849746e-02],\n",
       "       [4.2629689e-02],\n",
       "       [7.9144537e-01],\n",
       "       [4.1681826e-03],\n",
       "       [2.8759420e-01]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8a1b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = list(binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "382e19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = np.asarray(binary_predictions).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e9fa0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[520  76]\n",
      " [276 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.87      0.75       596\n",
      "         1.0       0.63      0.32      0.42       404\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.64      0.59      0.58      1000\n",
      "weighted avg       0.64      0.65      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true=y_test, y_pred=binary_predictions))\n",
    "print(classification_report(y_true=y_test, y_pred=binary_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
