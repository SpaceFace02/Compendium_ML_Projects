{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Tfidf vectorizer transforms the text to tfidf , also it count vectorizes it.\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report , confusion_matrix ,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASSIVE-AGGRESSIVE ALGORITHMS\n",
    "\n",
    "Passive-Aggressive algorithms are generally used for large-scale learning. It is one of the few ‘online-learning algorithms‘. In online machine learning algorithms, the input data comes in sequential order and the machine learning model is updated step-by-step, as opposed to batch learning, where the entire training dataset is used at once. This is very useful in situations where there is a huge amount of data and it is computationally infeasible to train the entire dataset because of the sheer size of the data. We can simply say that an online-learning algorithm will get a training example, update the classifier, and then throw away the example.\n",
    "\n",
    "A very good example of this would be to detect fake news on a social media website like Twitter, where new data is being added every second. To dynamically read data from Twitter continuously, the data would be huge, and using an online-learning algorithm would be ideal.\n",
    "\n",
    "Passive-Aggressive algorithms are somewhat similar to a Perceptron model, in the sense that they do not require a learning rate. However, they do include a regularization parameter.\n",
    "\n",
    "Passive: If the prediction is correct, keep the model and do not make any changes. i.e., the data in the example is not enough to cause any changes in the model. \n",
    "Aggressive: If the prediction is incorrect, make changes to the model. i.e., some change to the model may correct it.\n",
    "\n",
    "\n",
    "### LINK1 - https://www.geeksforgeeks.org/passive-aggressive-classifiers/\n",
    "### LINK2 - https://www.youtube.com/watch?v=TJU8NfDdqNQ&ab_channel=VictorLavrenko\n",
    "\n",
    "Important parameters:\n",
    "\n",
    "C : This is the regularization parameter, and denotes the penalization the model will make on an incorrect prediction.\n",
    "\n",
    "max_iter : The maximum number of iterations the model makes over the training data.\n",
    "\n",
    "tol : The stopping criterion. If it is set to None, the model will stop when (loss > previous_loss  –  tol). By default, it is set to 1e-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a TfidfVectorizer?\n",
    "TF (Term Frequency): The number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.\n",
    "\n",
    "IDF (Inverse Document Frequency): Words that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.\n",
    "\n",
    "The TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features.\n",
    "\n",
    "### What is a PassiveAggressiveClassifier?\n",
    "Passive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0' ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {'FAKE':0 , 'REAL':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Let’s initialize a TfidfVectorizer with stop words from the English language and a \n",
    "maximum document frequency of 0.7 (terms with a higher document frequency will be discarded).\n",
    "Stop words are the most common words in a language that are to be filtered out before processing the natural language data. \n",
    "And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.'''\n",
    "\n",
    "bow_transformer = TfidfVectorizer(stop_words='english' ,max_df=0.7)\n",
    "tfidf_train=bow_transformer.fit_transform(X_train) \n",
    "tfidf_test = bow_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=0.62, max_iter=50, tol=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier(max_iter=50 ,C=0.62 ,tol=None)\n",
    "pac.fit(tfidf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9368587213891081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       630\n",
      "           1       0.94      0.94      0.94       637\n",
      "\n",
      "    accuracy                           0.94      1267\n",
      "   macro avg       0.94      0.94      0.94      1267\n",
      "weighted avg       0.94      0.94      0.94      1267\n",
      "\n",
      "[[589  41]\n",
      " [ 39 598]]\n",
      "Accuracy ,rounded off: 93.69%\n"
     ]
    }
   ],
   "source": [
    "y_pred = pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)\n",
    "print(classification_report(y_pred , y_test))\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(f'Accuracy ,rounded off: {round(score*100,2)}%')  # Round up to 2 decimal places.\n",
    "\n",
    "\n",
    "# Accuracy of 93.69% and a very good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()  # Balanced Dataset , that's why its such a good model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
